# ForgeServe Configuration Examples

This directory contains example `forgeserve.yaml` configuration files demonstrating various ways to deploy LLM serving backends using ForgeServe.

Use these as a starting point for your own deployments.

## Examples

*   **`vllm_basic_gpu.yaml`**: Minimal configuration to deploy a model using vLLM on a single GPU.
*   **`ollama_cpu_only.yaml`**: Shows how to deploy a model using the Ollama adapter targeting CPU resources only.

Refer to the main project documentation for a full list of configuration options and their descriptions.